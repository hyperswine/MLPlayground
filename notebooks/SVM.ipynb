{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "Since the data isn't in entirely the best form, e.g. missing values, unordered values, makes it quite difficult to simply\n",
    "plug the values into a label encoder. The fact that there are also a considerable number of features (~20), and the corresponding\n",
    "number of examples are low (700-800), it makes sense to test SVM's with different kernels and inspect its performance.\n",
    "\n",
    "This will thus better deal with high variance and deal with bias implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Load scripts to clean and generate data\n",
    "# noinspection PyUnresolvedReferences\n",
    "from auxiliary.data_clean2 import clean_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('dataset/GSMArena_dataset_2020.csv', index_col=0)\n",
    "\n",
    "data_features = data[[\"oem\", \"launch_announced\", \"launch_status\", \"body_dimensions\", \"display_size\", \"comms_wlan\", \"comms_usb\",\n",
    "                \"features_sensors\", \"platform_os\", \"platform_cpu\", \"platform_gpu\", \"memory_internal\",\n",
    "                \"main_camera_single\", \"main_camera_video\", \"misc_price\",\n",
    "                \"selfie_camera_video\",\n",
    "                \"selfie_camera_single\", \"battery\"]]\n",
    "\n",
    "# Clean up the data into a trainable form.\n",
    "df = clean_data(data_features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Learning the SVM\n",
    "\n",
    "Using sk-learn, it is possible to plug in the data and fit a model.\n",
    "Most of the kernel functions will be tested with 4-F cross-validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_classify_five(y):\n",
    "    if y>1000:\n",
    "        return 4\n",
    "    elif y>700 and y<=1000:\n",
    "        return 3\n",
    "    elif y>450 and y<=700:\n",
    "        return 2\n",
    "    elif y>200 and y<=450:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def y_classify(y):\n",
    "    if y>700:\n",
    "        return 2\n",
    "    elif y>=300 and y<=700:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now its time to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"misc_price\"]\n",
    "y3 = y.apply(y_classify)\n",
    "X = df.drop([\"key_index\", \"misc_price\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y3, random_state=120, test_size=.3)\n",
    "\n",
    "y5 = y.apply(y_classify_five)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y5, random_state=120, test_size=.3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svm_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"3 class accuracy: \", accuracy_score(y_test,y_pred))\n",
    "\n",
    "svm_clf.fit(X_train5,y_train5)\n",
    "\n",
    "y_pred5 = svm_clf.predict(X_test5)\n",
    "print(\"5 class accuracy: \", accuracy_score(y_test5,y_pred5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Analyzing the model and results\n",
    "\n",
    "As seen, we have fitted a preliminary SVM model to the training data.\n",
    "Using matplotlib, it is possible to visualize the model & preliminary performance.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cross-Validation & Performance Tuning\n",
    "\n",
    "We now implement our own SVM using the dual lagragian with hinge loss. We then test all the possible kernel mappings, linear, polynomial, euclidean, sigmoid.\n",
    "\n",
    "As one may see, the preliminary performance is a considerable [improvement] to the LR model.\n",
    "\n",
    "By tuning some more parameters & using different kernel functions, it may be possible to further increase the training & testing performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperSVM:\n",
    "    \"\"\"\n",
    "    A support-vector machine with multiple kernel mappings for high \n",
    "    dimensions & hinge loss. Uses a One-vs-One strategy for multiclass classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, dual=True):\n",
    "        self.dual = dual\n",
    "        self.svm_models = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit m(m-1)/2 models in 'ovo' manner, given m features.\n",
    "        NOTE: Maximum 30 features = 435 models. Assumes that X.shape[1] contains number of features.\n",
    "        \"\"\"\n",
    "        self.svm_models = []\n",
    "        for feature_i in X.features:\n",
    "            # add each model\n",
    "            self.svm_models.append([fit_model(feature_i, feature_j) for feature_j in X.features])\n",
    "\n",
    "    \n",
    "    def fit_model(i,j):\n",
    "        \"\"\"\n",
    "        i - numpy series of a feature column.\n",
    "        j - numpy series of another feature column.\n",
    "        \"\"\"\n",
    "        # fit a linear svm. TODO: change this to non-linear\n",
    "        pass\n",
    "\n",
    "\n",
    "    def partial_lagrangian(self, L, var):\n",
    "        \"\"\"\n",
    "        Calculates the partial lagriangian derivative with respect to var.\n",
    "        Minimizes hinge loss -> maximizes dual.\n",
    "\n",
    "        Return - A binary SVM that outputs a score for each class according to its euclidean distance from the maximum-separating-hyperplane.\n",
    "        NOTE: positive score for the side of the 'positive' (first) class, negative otherwise.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Input data into all models & retreive an output and its associated 'score'.\n",
    "        The class with the highest total score is the predicted class.\n",
    "\n",
    "        Return - 1xm list of predictions.\n",
    "        \"\"\"\n",
    "        # append the score for each output feature\n",
    "        # scores_pair are stored as \"(feature 1, feature 2)\": \"(score 1, score 2)\" mappings\n",
    "        scores_pair = {}\n",
    "        prediction = []\n",
    "        # main loop to predict all examples\n",
    "        for index, example in X.iterrows():\n",
    "            for svm_mod in self.svm_models:\n",
    "                # TODO: each SvmMod class should have a predict function which takes in a length m row\n",
    "                # each SvmMod should also have 2 feature names so it can automatically take the 2 feature values of that row\n",
    "                scores_pair[svm_mod.feature1] = svm_mod.predict(example)\n",
    "\n",
    "            # retreive the feature with the highest total score & append to prediction       \n",
    "            prediction.append(arg_max(scores_pair))\n",
    "            # reset scores pair to predict next example\n",
    "            scores_pair = {}\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def performance(self, y_test, y_pred):\n",
    "        \"\"\"\n",
    "        Output accuracy score.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class SvmMod:\n",
    "    \"\"\"\n",
    "    Representation of a binary, (currently) linear SVM.\n",
    "    \"\"\"\n",
    "    def __init__(self, class1, class2):\n",
    "        self.classes = (class1, class2)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Expect - dataframe of two feature columns.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Return - tuple containing scores for class1 & class2\n",
    "        \"\"\"\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kernel function [1]\n",
    "\n",
    "# 4-F Cross-Validation on [1]\n",
    "\n",
    "# Performance Insights\n",
    "\n",
    "\n",
    "\n",
    "# Kernel function [2]\n",
    "\n",
    "# 4-F Cross-Validation on [2]\n",
    "\n",
    "# Performance Insights\n",
    "\n",
    "\n",
    "\n",
    "# Kernel function [3]\n",
    "\n",
    "# 4-F Cross-Validation on [2]\n",
    "\n",
    "# Performance Insights\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plots & Analysis of different Kernel methods\n",
    "\n",
    "[Write Here]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}